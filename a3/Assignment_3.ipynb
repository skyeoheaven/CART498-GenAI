{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r7h-EApiswg0"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=(OPENAI_API_KEY))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PERSONALITY = [\n",
        "    \"Nice! I got it right. I AM the calculator now.\",\n",
        "    \"Okay that one felt lucky.\",\n",
        "    \"Hmm... I think I understand multiplication.\",\n",
        "]\n",
        "FAIL_MESSAGES = [\n",
        "    \"Wow, I messed up again. Math is hard, okay?\",\n",
        "    \"Numbers keep moving when I look away.\",\n",
        "    \"I regret choosing a STEM career.\",\n",
        "    \"Please stop making me square things.\",\n",
        "    \"I was trained on literature, not suffering.\",\n",
        "    \"I am a language model. LANGUAGE. NOT NUMBER MODEL.\",\n",
        "    \"I feel my parameters dissolving into noise.\"\n",
        "]\n",
        "def ai_multiply(a, b):\n",
        "    \"\"\"\n",
        "    Ask GPT-4.1 to multiply two numbers.\n",
        "    We intentionally rely on the LLM instead of Python.\n",
        "    \"\"\"\n",
        "    prompt = f\"What is {a} * {b}? Respond ONLY with the number.\"\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4.1-nano\",\n",
        "        input=prompt,\n",
        "        max_output_tokens=20\n",
        "    )\n",
        "    text = response.output_text.strip()\n",
        "    try:\n",
        "        return int(text)\n",
        "    except:\n",
        "        return None\n",
        "def run_iterations(n, iterations):\n",
        "    current = n\n",
        "    failures = 0\n",
        "    print(f\"\\nStarting number: {n}\")\n",
        "    print(f\"Iterations: {iterations}\\n\")\n",
        "    for step in range(1, iterations + 1):\n",
        "        correct = current * current\n",
        "        ai_result = ai_multiply(current, current)\n",
        "        print(f\"Step {step}: {current} * {current}\")\n",
        "        if ai_result == correct:\n",
        "            print(f\"AI Answer: {ai_result} ✓\")\n",
        "            msg_index = min(step-1, len(PERSONALITY)-1)\n",
        "            print(PERSONALITY[msg_index])\n",
        "        else:\n",
        "            failures += 1\n",
        "            print(f\"AI Answer: {ai_result} ✗\")\n",
        "            print(f\"Correct : {correct}\")\n",
        "            fail_index = min(failures-1, len(FAIL_MESSAGES)-1)\n",
        "            print(FAIL_MESSAGES[fail_index])\n",
        "        print(\"-\" * 40)\n",
        "        current = correct\n",
        "if __name__ == \"__main__\":\n",
        "    n = int(input(\"Enter base number (n): \"))\n",
        "    i = int(input(\"Enter iterations (i): \"))\n",
        "    run_iterations(n, i)"
      ],
      "metadata": {
        "id": "fUVxPX_W37sv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}